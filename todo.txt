done:
parameter an die spiders geben, um den zeitraum zu steuern, den sie ancrawlen
   http://stackoverflow.com/questions/15611605/how-to-pass-a-user-defined-argument-in-scrapy-spider

undone:
"scrapy crawlall" mit argument versehen, um eine elasticsearch-instanz angeben zu können
das projekt für andere nutzbar machen. maven nutzen?
was kann man mit literaturverweisen (z.b. von vox.org) machen?
den code nach fehlenden typprüfungen untersuchen
eine generische fetch_json_doc-methode schreiben (krugmann und upshot)
den scrapy-internen logging
mechanismus verwenden
